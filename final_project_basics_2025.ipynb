{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buJeccWRZX26"
      },
      "source": [
        "# Part 0 - Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52FrgSEzQYWb"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVQDuMr52due"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import kagglehub\n",
        "import scipy.io\n",
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hxROtsyjWPW"
      },
      "source": [
        "## Dataset <font color='red'>GET READY FOR SUBMISSION\n",
        "Cars196 - 196 different classes of vehicles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlSkIXYtYQi_"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mE101DNL0g4L"
      },
      "outputs": [],
      "source": [
        "#@title Download from kaggle\n",
        "download_from_kaggle = False #@param {type:\"boolean\"}\n",
        "# Download latest version\n",
        "if download_from_kaggle:\n",
        "    path = kagglehub.dataset_download(\"jessicali9530/stanford-cars-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mZRrRykA3kWw"
      },
      "outputs": [],
      "source": [
        "#@title Move data to new directory\n",
        "!mkdir /content/dataset\n",
        "if download_from_kaggle:\n",
        "    !mv /root/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2/* /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ciF9Zrs3UL1h"
      },
      "outputs": [],
      "source": [
        "#@title Create and set data path - connect to drive if necessary\n",
        "\n",
        "#@markdown > We suggest to use this as the path to the directory containing this notebook\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/ImageMulticlassClassification/' #@param {\"type\":\"string\"}\n",
        "\n",
        "use_drive_path = True #@param {type:\"boolean\"}\n",
        "if use_drive_path:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "#@markdown > The default path if you don't use the drive path is `/content/dataset/`\n",
        "\n",
        "# Set data directory path\n",
        "data_dir = PATH + 'dataset/' if use_drive_path else '/content/dataset/'\n",
        "\n",
        "# Make sure to create the path if it's missing\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "print(f'{data_dir=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P4IGp2VWWWPV"
      },
      "outputs": [],
      "source": [
        "#@title Copy data to drive\n",
        "#@markdown the data will be copied to `data_dir`\n",
        "copy_data_to_data_dir = False #@param {type:\"boolean\"}\n",
        "if copy_data_to_data_dir:\n",
        "    os.system(f\"!cp -r /content/dataset/* {data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tc5iYhSswIsX"
      },
      "outputs": [],
      "source": [
        "#@title Get Annotations File from google drive <font color='red'> - CHANGE FILE ID (הוא מסביר בסרטון בדקה 13 איך עושים את זה)\n",
        "!gdown 1Mmcu4btdVorH9S6QH6qbhTl1UrVx217o # Change this id\n",
        "\n",
        "metadata_file_path = data_dir + 'stanford_cars_with_class_names.xlsx'\n",
        "\n",
        "os.system(f'!mv /content/stanford_cars_with_class_names.xlsx {metadata_file_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TGYg8eraza6"
      },
      "source": [
        "## Load MetaData\n",
        "\n",
        "Extract image names, class names and numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2_iFonipC9os"
      },
      "outputs": [],
      "source": [
        "#@title Load metadata for train and test sets <font color='red'> CHANGE PATH\n",
        "\n",
        "# Take the last 3 columns with image name, class name and class number\n",
        "train_annotations = pd.read_excel(metadata_file_path, sheet_name='train').iloc[:, -1:-4:-1]\n",
        "test_annotations = pd.read_excel(metadata_file_path, sheet_name='test').iloc[:, -1:-4:-1]\n",
        "\n",
        "# For some reason the labels in the test annotations file load with additional unnecessary \\'\\s\n",
        "test_annotations.image = test_annotations.image.str.strip(\"'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0TTEymPZe0-x"
      },
      "outputs": [],
      "source": [
        "#@title Create the Models dir if not existing <font color='red'> - change `models_dir` as needed\n",
        "models_dir = PATH + 'models/'\n",
        "# models_dir = '/content/models/'\n",
        "\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dhzyOZxMtuR6"
      },
      "outputs": [],
      "source": [
        "#@title Dowload and unzip ZIP from Drive <font color=\"red\"> - You need to set this up\n",
        "#@markdown Should contain `dataset` and `models` directories\n",
        "!gdown #<YOURZIPFILEID>\n",
        "!unzip #<YOURZIPFILE>.zip\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxFQGdYzYffQ"
      },
      "source": [
        "## Plot Single Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "85_xmQfsIO0g"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions\n",
        "%%script echo skipping\n",
        "def get_class_and_model(image_name: str, annotations: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Get the class number and model name for a given image name.\n",
        "\n",
        "    Args:\n",
        "        image_name (str): The image file name (e.g., \"00001.jpg\").\n",
        "        annotations: Annotations from the .mat file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (class_number, model_name) if found, otherwise raises an error.\n",
        "    \"\"\"\n",
        "    if image_name not in annotations.image.values:\n",
        "        raise ValueError(f\"Image {image_name} not found in annotations.\")\n",
        "\n",
        "    class_number = annotations[annotations.image == image_name].values[0,1]\n",
        "    model_name = annotations[annotations.image == image_name].values[0,2]\n",
        "    return class_number, model_name\n",
        "\n",
        "def show_image_with_title(image_name, dataset_path, annotations):\n",
        "    \"\"\"\n",
        "    Display an image with its class and model name as the title.\n",
        "\n",
        "    Args:\n",
        "        image_name (str): The name of the image file (e.g., \"car_ims/000001.jpg\").\n",
        "        dataset_path (str): Path to the dataset containing the images.\n",
        "        annotations: Annotations from the .mat file.\n",
        "        class_names_list: List of class names extracted from the .mat file.\n",
        "    \"\"\"\n",
        "    # Get class number and model name for the image\n",
        "    class_number, model_name = get_class_and_model(image_name, annotations)\n",
        "\n",
        "    # Construct the title\n",
        "    title = f\"Class {class_number} → \\\"{model_name}\\\"\"\n",
        "    updated_img_path = image_name.replace(\"car_ims/0\", \"\")\n",
        "    # Load and display the image\n",
        "    image_path = os.path.join(dataset_path, updated_img_path)\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Image file not found: {image_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98GQoAdAFy2t"
      },
      "source": [
        "### Example usage\n",
        "\n",
        "\n",
        "*   **Image Name**: car_ims/000001.jpg\n",
        "*   **Class Number**: 1\n",
        "*   **Model Name**: \"AM General Hummer SUV 2000\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2hA5R_vRFuGj"
      },
      "outputs": [],
      "source": [
        "#@title Extract metadata\n",
        "%%script echo skipping\n",
        "example_image_name = train_annotations.loc[0,'image']\n",
        "example_class, example_model = get_class_and_model(example_image_name, train_annotations)\n",
        "\n",
        "example_image_name, example_class, example_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fy2wHS2HGWKq"
      },
      "outputs": [],
      "source": [
        "#@title Show example\n",
        "%%script echo skipping\n",
        "dataset_path = data_dir + \"cars_train/cars_train\"\n",
        "show_image_with_title(example_image_name, dataset_path, train_annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k63OhROC5Imc"
      },
      "source": [
        "---\n",
        "# Part 1 - Pre-processing and general set-up <font color=\"red\"> - check befor running parts 2 to 4\n",
        "\n",
        "you can also choose partial data for code testing purposes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uanVEkUi2_7j"
      },
      "source": [
        "## 1.1 Define hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "748xIp_Z3KQ-"
      },
      "source": [
        "Here we define important settings (hyperparameters) for training our deep learning models.\n",
        "> `IMG_SIZE` sets the image size to 224 pixels.\n",
        ">\n",
        ">`NUM_CLASSES` specifies 196 different car types.\n",
        ">\n",
        ">`BATCH_SIZE` sets the training batch size to.\n",
        ">\n",
        ">`EPOCHS` sets the number of training runs.\n",
        ">\n",
        ">`VAL_SPLIT` fraction of the datato allocate for validation.\n",
        "\n",
        "These settings influence how the model learns and performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NpTSKiCK5Imc"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224  #@param # EfficientNetV2L expects 224x224 images\n",
        "NUM_CLASSES = 196 #@param\n",
        "BATCH_SIZE = 16 #@param {\"type\":\"integer\"}\n",
        "EPOCHS = 3 #@param {\"type\":\"integer\"}\n",
        "VAL_SPLIT = 0.2 #@param {\"type\":\"number\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO7sT7jJ2ZDN"
      },
      "source": [
        "## 1.2 Define Data augmentation layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79dbPBAH2vnV"
      },
      "source": [
        "\n",
        "The data augmentation transformations I used:\n",
        "\n",
        "1.  **`tf.keras.layers.RandomFlip(\"horizontal\")`**: This layer randomly flips images horizontally.  Half the time the image will be flipped, and half the time it will not.  This helps the model learn that an object is the same regardless of its left-right orientation.\n",
        "\n",
        "2.  **`tf.keras.layers.RandomRotation(0.2)`**: This layer randomly rotates images by up to 20% of a full rotation (0.2 * 360 degrees = 72 degrees).  So, the model will see slightly rotated versions of the images. This makes the model robust to small variations in the angle of the object in an image.\n",
        "\n",
        "3.  **`tf.keras.layers.RandomTranslation(0.2, 0.2)`**: This layer randomly translates images both horizontally and vertically by up to 20% of the image size. This shifts the image slightly, making the model less sensitive to the exact position of the object.\n",
        "\n",
        "4.  **`tf.keras.layers.RandomZoom(0.2)`**:  This layer randomly zooms into images by up to 20%. This introduces different levels of zoom, forcing the model to generalize to images with different scales of objects.\n",
        "\n",
        "5.  **`tf.keras.layers.RandomBrightness(0.2)`**: This layer randomly adjusts the brightness of images by up to 20%. This augmentation helps the model to be less sensitive to changes in lighting conditions.\n",
        "\n",
        "6.  **`tf.keras.layers.RandomContrast(0.2)`**: This layer randomly adjusts the contrast of images by up to 20%.  Similar to brightness augmentation, this makes the model more robust to variations in image contrast.\n",
        "\n",
        "\n",
        "In essence, these transformations create slightly altered versions of the original images, which helps train a more robust model that performs better on unseen data and is less prone to overfitting.  The model learns features that are invariant to small changes in orientation, position, scale, brightness and contrast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WfngIaeW1NFv"
      },
      "outputs": [],
      "source": [
        "#@title Augmentations\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomBrightness(0.2),\n",
        "    tf.keras.layers.RandomContrast(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5jUMFt22469"
      },
      "source": [
        "## 1.3 Process Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aYK1L-ciYGu3"
      },
      "outputs": [],
      "source": [
        "#@title Load dataset functions\n",
        "def vectorize_label(index, length):\n",
        "    \"\"\"\n",
        "    Creates a TensorFlow tensor of zeros with length 'length', and sets the element at 'index' to 1.\n",
        "    Args:\n",
        "        length: The desired length of the tensor.\n",
        "        index: The index of the element to set to 1.\n",
        "    Returns:\n",
        "        A TensorFlow tensor of shape (length,) with a 1 at the specified index and 0 elsewhere.\n",
        "    \"\"\"\n",
        "    if index < 0 or index >= length:\n",
        "        print(\"Error: Index out of bounds.\")\n",
        "        return None\n",
        "    tensor = tf.zeros(length, dtype=tf.int32)\n",
        "    tensor = tf.tensor_scatter_nd_update(tensor, [[index]], [1])\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def create_dataset_from_directory_and_metadata(data_dir, annotations, img_size, batch_size, val_split=0) -> tf.data.Dataset:\n",
        "    # create image names and labels lists\n",
        "    image_paths = list(data_dir + annotations.values[:,0])\n",
        "    labels = annotations.values[:,2] - 1 # Make the first label 0 and the last is 195\n",
        "    labels = [vectorize_label(label, NUM_CLASSES) for label in labels]\n",
        "\n",
        "    # import pdb ; pdb.set_trace()\n",
        "\n",
        "    # create tf dataset object\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "\n",
        "    # pre-split processing\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "\n",
        "    if val_split > 0:\n",
        "        # Split dataset\n",
        "        val_size = int(len(image_paths) * val_split)\n",
        "        train_dataset = dataset.skip(val_size)\n",
        "        val_dataset = dataset.take(val_size)\n",
        "\n",
        "        # Batch datasest\n",
        "        train_dataset = train_dataset.batch(batch_size)\n",
        "        val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "        return train_dataset, val_dataset\n",
        "    else:\n",
        "        return dataset.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v1ZOjDqm-gY-"
      },
      "outputs": [],
      "source": [
        "#@title Get train, validation and test datasets\n",
        "train_ds, val_ds = create_dataset_from_directory_and_metadata(\n",
        "    data_dir + 'cars_train/cars_train/',\n",
        "    train_annotations, IMG_SIZE, BATCH_SIZE, VAL_SPLIT)\n",
        "\n",
        "test_ds = create_dataset_from_directory_and_metadata(\n",
        "    data_dir + 'cars_test/cars_test/',\n",
        "    test_annotations, IMG_SIZE, BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xY9Z5xVq5ZNt"
      },
      "outputs": [],
      "source": [
        "#@title Prepare datasets for model training and evaluation\n",
        "# Apply data augmentation to training set\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (data_augmentation(x, training=True), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "\n",
        "# Normalize pixel values\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Optimize performance\n",
        "prefetch = False #@param {\"type\":\"boolean\"}\n",
        "if prefetch:\n",
        "    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "    val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Training samples: {len(train_ds) * BATCH_SIZE}\")\n",
        "print(f\"Validation samples: {len(val_ds) * BATCH_SIZE}\")\n",
        "print(f\"Test samples: {len(test_ds) * BATCH_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rlAgKYUlYCFl"
      },
      "outputs": [],
      "source": [
        "#@title Take a subset of the data <font color='red'> - for code testing purposes\n",
        "take_partial_data = False #@param {type:\"boolean\"}\n",
        "how_many_batches = 3 #@param {\"type\":\"integer\"}\n",
        "\n",
        "if take_partial_data:\n",
        "    train_ds = train_ds.take(how_many_batches)\n",
        "    val_ds = val_ds.take(how_many_batches)\n",
        "    test_ds = test_ds.take(how_many_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96gFw_fFaPRH"
      },
      "source": [
        "## 1.4 Get base model for Transfer learning and embedding\n",
        "\n",
        "I chose EfficientNetV2L with `imagenet` weights as the base model\n",
        "\n",
        "It offers:\n",
        "\n",
        "- High accuracy and efficiency\n",
        "- Pre-trained knowledge from ImageNet\n",
        "- Feature extraction capabilities\n",
        "- Faster training\n",
        "- Good performance in transfer learning scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6pp3dO5U3oxa"
      },
      "outputs": [],
      "source": [
        "#@title Get Base Model\n",
        "from tensorflow.keras.applications import EfficientNetV2L\n",
        "\n",
        "donload_new_base_model = True #@param {type:\"boolean\"}\n",
        "#@markdown make sure you have a `\"base_model.keras\"` file in `models_dir` if you set the following True\n",
        "load_from_models_dir = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if donload_new_base_model:\n",
        "    # Load the pre-trained model\n",
        "    base_model = EfficientNetV2L(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "elif load_from_models_dir:\n",
        "    base_model = tf.keras.models.load_model(models_dir + '/base_model.keras')\n",
        "else:\n",
        "    raise ValueError(\"Please set either `donload_new_base_model` or `load_from_models_dir` to True\")\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA_aNqWTjTZw"
      },
      "source": [
        "## 1.5 Define evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AEawf0l1hhKm"
      },
      "outputs": [],
      "source": [
        "#@title Single Model evaluation functions\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def plot_accuracy_along_training(history):\n",
        "    \"\"\"\n",
        "    Plots the training and validation accuracy curves from a Keras model's history.\n",
        "\n",
        "    Args:\n",
        "        history: The history object returned by the Keras model's fit method.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def test_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro') # Use 'macro' for multi-class\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Assuming y_test and y_pred are already defined from your model predictions on the test set\n",
        "def test_DL_model(model, test_ds):\n",
        "    y_pred = model.predict(test_ds)\n",
        "    y_pred = np.argmax(y_pred, axis=1) # Convert probabilities to class labels\n",
        "\n",
        "    y_true = []\n",
        "    for images, labels in test_ds:\n",
        "        y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    y_true = np.array(y_true)\n",
        "\n",
        "    return test_model(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Cj0SpqOpjotJ"
      },
      "outputs": [],
      "source": [
        "#@title Compare experiment functions\n",
        "def plot_comparison(histories, metrics):\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for i, history in enumerate(histories):\n",
        "        for metric in metrics:\n",
        "            plt.plot(history.history[metric], label=f'Experiment {i+1} - {metric}')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Value')\n",
        "    plt.title('Comparison of Training Histories')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def compare_test_results(results):\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "    df = pd.DataFrame(results, columns=metrics)\n",
        "    df.index = [f'Experiment {i+1}' for i in range(len(results))]\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TabuNlsvNmM7"
      },
      "outputs": [],
      "source": [
        "#@title Save model function\n",
        "def save_tf_model(model, model_dir, model_name):\n",
        "    \"\"\"Saves a TensorFlow model to a specified directory.\n",
        "\n",
        "    Args:\n",
        "        model: The TensorFlow model to save.\n",
        "        model_dir: The directory to save the model in.\n",
        "        model_name: The name to give the saved model.\n",
        "    \"\"\"\n",
        "\n",
        "    model_path = os.path.join(model_dir, model_name)\n",
        "    model.save(model_path)\n",
        "    print(f\"Model saved to: {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1PkbxlR5Imc"
      },
      "source": [
        "---\n",
        "# Part 2 - Transfer Learning Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Transfer Learning experiments explore different architectures built on top of EfficientNetV2L, focusing on the trade-off between model capacity and regularization:\n",
        "\n",
        "1. **Base Configuration (Experiment 1)**:\n",
        "   - Single dense layer (1024 units) with moderate dropout (0.5)\n",
        "   - Balanced approach between complexity and regularization\n",
        "   - Serves as baseline for comparison\n",
        "   - Minimalist architecture to test if simple feature mapping is sufficient\n",
        "\n",
        "2. **Enhanced Architecture (Experiment 2)**:\n",
        "   - Two dense layers (1024 units each) with dropout (0.5) between them\n",
        "   - Increased model capacity for more complex feature relationships\n",
        "   - Additional layer allows hierarchical feature learning\n",
        "   - Higher parameter count but potential for better feature abstraction\n",
        "\n",
        "3. **High Regularization (Experiment 3)**:\n",
        "   - Single dense layer (1024 units) with aggressive dropout (0.8)\n",
        "   - Tests impact of stronger regularization\n",
        "   - Focuses on preventing overfitting\n",
        "   - Same capacity as base model but more conservative in feature utilization\n",
        "\n",
        "Key differences:\n",
        "- Experiment 1 vs 2: Tests if additional capacity improves performance\n",
        "- Experiment 2 vs 3: Compares complex architecture against stronger regularization\n",
        "- Experiment 1 vs 3: Evaluates impact of dropout strength on same architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayBUa11D1B1P"
      },
      "source": [
        "## 2.1 Set-up\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xv3BhzQmrg8w"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-ooOlFUbz9"
      },
      "source": [
        "## 2.2 Expirement 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M3KjD6-V5Imc"
      },
      "outputs": [],
      "source": [
        "#@title Define Model\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "tl1_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "tl1_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "tl1_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1CYn9nNqmhop"
      },
      "outputs": [],
      "source": [
        "#@title Load a pretrained model\n",
        "#@markdown Loading from the set `models_dir`\n",
        "# Load the pre-trained model\n",
        "model_name = \"tl1_model\" # @param {\"type\":\"string\"}\n",
        "model_path = models_dir + f'/{model_name}.keras' # Replace with the actual path to your saved model\n",
        "tl1_model = tf.keras.models.load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gdKb1UyQDEyc"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "tl1_history = tl1_model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lEBiCA14jP0y"
      },
      "outputs": [],
      "source": [
        "#@title Show training loss and accuracy\n",
        "plot_accuracy_along_training(tl1_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nuYj0B4ajRQy"
      },
      "outputs": [],
      "source": [
        "#@title Test Model\n",
        "accuracy_1, precision_1, recall_1, f1_1 = test_DL_model(tl1_model, test_ds)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_1}\")\n",
        "print(f\"Test Precision: {precision_1}\")\n",
        "print(f\"Test Recall: {recall_1}\")\n",
        "print(f\"Test F1-score: {f1_1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QoAsbzX3sNHK"
      },
      "outputs": [],
      "source": [
        "#@title Save model\n",
        "model_name = \"tl1_model\" #@param {\"type\":\"string\"}\n",
        "save_tf_model(tl1_model, models_dir, f'{model_name}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_kloeRLnSvy"
      },
      "source": [
        "## 2.3 Expirement 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mFkMEhHonSvz"
      },
      "outputs": [],
      "source": [
        "#@title Define Model\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "tl2_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "tl2_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "tl2_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RBBEaZiYoFvd"
      },
      "outputs": [],
      "source": [
        "#@title Load a pretrained model\n",
        "#@markdown Loading from the set `models_dir`\n",
        "# Load the pre-trained model\n",
        "model_name = \"tl2_model\" # @param {\"type\":\"string\"}\n",
        "model_path = models_dir + f'/{model_name}.keras' # Replace with the actual path to your saved model\n",
        "tl2_model = tf.keras.models.load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3VM5jIELnSvz"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "tl2_history = tl2_model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c2sFsxoKnSvz"
      },
      "outputs": [],
      "source": [
        "#@title Show training loss and accuracy\n",
        "plot_accuracy_along_training(tl2_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xTeWduuFnSvz"
      },
      "outputs": [],
      "source": [
        "#@title Test Model\n",
        "accuracy_2, precision_2, recall_2, f1_2 = test_DL_model(tl2_model, test_ds)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_2}\")\n",
        "print(f\"Test Precision: {precision_2}\")\n",
        "print(f\"Test Recall: {recall_2}\")\n",
        "print(f\"Test F1-score: {f1_2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lOZuecDLsIVt"
      },
      "outputs": [],
      "source": [
        "#@title Save model\n",
        "model_name = \"tl2_model\" #@param {\"type\":\"string\"}\n",
        "save_tf_model(tl2_model, models_dir, f'{model_name}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r61WOFZnVDv"
      },
      "source": [
        "## 2.4 Expirement 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CsM4xix2nVDw"
      },
      "outputs": [],
      "source": [
        "#@title Define Model\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.8)(x)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "tl3_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "tl3_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "tl3_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0cmlghzkoTy9"
      },
      "outputs": [],
      "source": [
        "#@title Load a pretrained model\n",
        "#@markdown Loading from the set `models_dir`\n",
        "# Load the pre-trained model\n",
        "model_name = \"tl3_model\" # @param {\"type\":\"string\"}\n",
        "model_path = models_dir + f'/{model_name}.keras' # Replace with the actual path to your saved model\n",
        "tl3_model = tf.keras.models.load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kNK1t-ednVDw"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "tl3_history = tl3_model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZQv6mP-unVDw"
      },
      "outputs": [],
      "source": [
        "#@title Show training loss and accuracy\n",
        "plot_accuracy_along_training(tl3_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g15OpTJMnVDw"
      },
      "outputs": [],
      "source": [
        "#@title Test Model\n",
        "accuracy_3, precision_3, recall_3, f1_3 = test_DL_model(tl3_model, test_ds)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_3}\")\n",
        "print(f\"Test Precision: {precision_3}\")\n",
        "print(f\"Test Recall: {recall_3}\")\n",
        "print(f\"Test F1-score: {f1_3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ohfk8ZAjr-df"
      },
      "outputs": [],
      "source": [
        "#@title Save model\n",
        "model_name = \"tl3_model\" #@param {\"type\":\"string\"}\n",
        "save_tf_model(tl3_model, models_dir, f'{model_name}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l0rYOK0MaSB"
      },
      "source": [
        "## 2.5 Compare Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xl2634YB0yj9"
      },
      "outputs": [],
      "source": [
        "#@title Results\n",
        "# Group history objects\n",
        "histories = [tl1_history, tl2_history, tl3_history]\n",
        "\n",
        "# Compare training history\n",
        "plot_comparison(histories, ['accuracy', 'val_accuracy', 'loss', 'val_loss'])  # Plot Accuracy and Validation Accuracy\n",
        "\n",
        "# Group metrics\n",
        "results = [\n",
        "    [accuracy_1, precision_1, recall_1, f1_1],\n",
        "    [accuracy_2, precision_2, recall_2, f1_2],\n",
        "    [accuracy_3, precision_3, recall_3, f1_3]\n",
        "]\n",
        "\n",
        "# Compare test metrics\n",
        "df_results = compare_test_results(results)\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaQod3W13qYK"
      },
      "source": [
        "## 2.6 Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hJpCWz3-xzjC"
      },
      "outputs": [],
      "source": [
        "#@title Save\n",
        "\n",
        "save_models = False #@param {type:\"boolean\"}\n",
        "model_type_name = 'tl' #@param {\"type\":\"string\"}\n",
        "\n",
        "\n",
        "if save_models:\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    tl1_model.save(os.path.join(models_dir, f'{model_type_name}_model_1_{timestamp}.keras'))\n",
        "    tl2_model.save(os.path.join(models_dir, f'{model_type_name}_model_2_{timestamp}.keras'))\n",
        "    tl3_model.save(os.path.join(models_dir, f'{model_type_name}_model_3_{timestamp}.keras'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaJTF4UK5Imc"
      },
      "source": [
        "---\n",
        "# Part 3 - Image Retrieval Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The KNN experiments explore different neighborhood sizes for classification using embeddings from EfficientNetV2L:\n",
        "\n",
        "1. **Small Neighborhood (k=3)**:\n",
        "   - Tighter, more specific neighborhood\n",
        "   - Higher sensitivity to local patterns\n",
        "   - May be more precise but susceptible to noise\n",
        "   - Best for distinct, well-separated classes\n",
        "\n",
        "2. **Medium Neighborhood (k=5)**:\n",
        "   - Balanced neighborhood size\n",
        "   - Moderate smoothing of decision boundaries\n",
        "   - Compromise between specificity and robustness\n",
        "   - Good for general-purpose classification\n",
        "\n",
        "3. **Large Neighborhood (k=10)**:\n",
        "   - Broader neighborhood consideration\n",
        "   - More robust to outliers\n",
        "   - Smoother decision boundaries\n",
        "   - Better for noisy or overlapping classes\n",
        "\n",
        "Key differences:\n",
        "- k=3 vs k=5: Tests impact of slightly larger neighborhood\n",
        "- k=5 vs k=10: Evaluates benefit of much broader context\n",
        "- k=3 vs k=10: Contrasts tight vs broad neighborhood effects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfcUXpw_nIxV"
      },
      "source": [
        "## 3.1 Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NDZ5nZeMm_uk"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY6awSYWo31Y"
      },
      "source": [
        "## 3.2 Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47NeLacFo6yh"
      },
      "source": [
        "KNN doesn't have a separate training phase where it learns parameters.\n",
        "\n",
        "It simply memorizes the training data.\n",
        "\n",
        "So we'll combine the training and validation data so we can learn from more data and hopefully get better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2_m0mLhk5zVy"
      },
      "outputs": [],
      "source": [
        "#@title Embedding the data using EfficientNetV2 with Imagenet weights - same base model used for TL\n",
        "def embed_data(embedding_model, dataset):\n",
        "    \"\"\"\n",
        "        This function transforms the data to a format that is suited for the KNN prediction head\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for images, labels in dataset:\n",
        "        image_embeddings = embedding_model.predict(images)\n",
        "        # Flatten the embeddings if needed\n",
        "        image_embeddings = image_embeddings.reshape(image_embeddings.shape[0], -1)\n",
        "        X.extend(image_embeddings)\n",
        "        y.extend(np.argmax(labels.numpy(), axis=1)) # Extract true class labels\n",
        "\n",
        "    return np.array(X),  np.array(y)\n",
        "\n",
        "# Embeddings\n",
        "X_train_embed, y_train_embed = embed_data(base_model, train_ds)\n",
        "X_val_embed, y_val_embed = embed_data(base_model, val_ds)\n",
        "X_test_embed, y_test_embed = embed_data(base_model, test_ds)\n",
        "\n",
        "# Combine X train and val since there is no weight learning in KNN we just memmorize\n",
        "X_train_embed = np.concatenate([X_train_embed, X_val_embed])\n",
        "y_train_embed = np.concatenate([y_train_embed, y_val_embed])\n",
        "\n",
        "print(f\"{X_train_embed.shape=} | {y_train_embed.shape=}\")\n",
        "print(f\"{X_test_embed.shape=} | {y_test_embed.shape=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCVnX8pcWu7s"
      },
      "source": [
        "## 3.3 Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WrPEmN1RpagK"
      },
      "outputs": [],
      "source": [
        "#@title Experiment 1 - k = 3\n",
        "knn_1 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_1.fit(X_train_embed, y_train_embed)\n",
        "y_pred_test_1 = knn_1.predict(X_test_embed)\n",
        "\n",
        "accuracy_1, precision_1, recall_1, f1_1 = test_model(y_pred_test_1, y_test_embed)\n",
        "\n",
        "print(\"Experiment 1 (k=3):\")\n",
        "print(f\"  Accuracy: {accuracy_1}\")\n",
        "print(f\"  Precision: {precision_1}\")\n",
        "print(f\"  Recall: {recall_1}\")\n",
        "print(f\"  F1-score: {f1_1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ea0N9IKboIbV"
      },
      "outputs": [],
      "source": [
        "#@title Experiment 2 - k = 5\n",
        "knn_2 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_2.fit(X_train_embed, y_train_embed)\n",
        "y_pred_test_2 = knn_2.predict(X_test_embed)\n",
        "\n",
        "accuracy_2, precision_2, recall_2, f1_2 = test_model(y_pred_test_2, y_test_embed)\n",
        "\n",
        "print(\"Experiment 2 (k=5):\")\n",
        "print(f\"  Accuracy: {accuracy_2}\")\n",
        "print(f\"  Precision: {precision_2}\")\n",
        "print(f\"  Recall: {recall_2}\")\n",
        "print(f\"  F1-score: {f1_2}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yc3PAUa3oK2P"
      },
      "outputs": [],
      "source": [
        "#@title Experiment 3 - k = 10\n",
        "knn_3 = KNeighborsClassifier(n_neighbors=10)\n",
        "knn_3.fit(X_train_embed, y_train_embed)\n",
        "y_pred_test_3 = knn_3.predict(X_test_embed)\n",
        "\n",
        "accuracy_3 = accuracy_score(y_test_embed, y_pred_test_3)\n",
        "precision_3 = precision_score(y_test_embed, y_pred_test_3, average='macro')\n",
        "recall_3 = recall_score(y_test_embed, y_pred_test_3, average='macro')\n",
        "f1_3 = f1_score(y_test_embed, y_pred_test_3, average='macro')\n",
        "\n",
        "print(\"Experiment 3 (k=10):\")\n",
        "print(f\"  Accuracy: {accuracy_3}\")\n",
        "print(f\"  Precision: {precision_3}\")\n",
        "print(f\"  Recall: {recall_3}\")\n",
        "print(f\"  F1-score: {f1_3}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfGP6AvSjGAb"
      },
      "source": [
        "## 3.4 Compare Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NdNXKfpjLFa"
      },
      "outputs": [],
      "source": [
        "# Group metrics\n",
        "results = [\n",
        "    [accuracy_1, precision_1, recall_1, f1_1],\n",
        "    [accuracy_2, precision_2, recall_2, f1_2],\n",
        "    [accuracy_3, precision_3, recall_3, f1_3]\n",
        "]\n",
        "\n",
        "# Compare test metrics\n",
        "df_results = compare_test_results(results)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdR3J2DA5Imc"
      },
      "source": [
        "---\n",
        "# Part 4 - E2E CNN Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEvw8t1z1P8"
      },
      "source": [
        "### 4.1 We chose ResNet type architecture for this experiment\n",
        "\n",
        "Open for more info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIh0BR2S1QBs"
      },
      "source": [
        "\n",
        "**ResNets are known for their ability to train very deep networks effectively by using skip connections (residual blocks) to address the vanishing gradient problem.**\n",
        "\n",
        "Here We define a simple ResNet (Residual Network) model for image classification.\n",
        "\n",
        "**`residual_block` function:**\n",
        "\n",
        "1. **`shortcut = x`:** Creates a copy of the input tensor `x` for the skip connection.\n",
        "\n",
        "2. **Convolutional Layers:** Applies two convolutional layers with batch normalization and ReLU activation to the input.\n",
        "\n",
        "3. **Shortcut Adjustment:** If necessary, adjusts the shortcut's dimensions using a 1x1 convolution and batch normalization to match the main processing path's output.\n",
        "\n",
        "4. **`x = Add()([x, shortcut])`:** Performs element-wise addition of the main path output and the shortcut, implementing the residual connection.\n",
        "\n",
        "5. **`x = Activation('relu')(x)`:** Applies ReLU activation to the sum.\n",
        "\n",
        "\n",
        "**`create_resnet_model` function:**\n",
        "\n",
        "1. **Input Layer:** Defines the input layer with the specified shape.\n",
        "\n",
        "2. **Initial Layers:** Applies a convolutional layer, batch normalization, ReLU activation, and max pooling for initial feature extraction.\n",
        "\n",
        "3. **Residual Blocks:** Adds a series of `residual_block`s to refine features.\n",
        "\n",
        "4. **Global Average Pooling:** Reduces spatial dimensions using global average pooling.\n",
        "\n",
        "5. **Output Layer:** Uses a dense layer with softmax activation for classification.\n",
        "\n",
        "6. **Model Creation:** Creates a Keras model with the defined input and output layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuration Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Custom ResNet experiments explore the impact of network depth through different numbers of residual blocks:\n",
        "\n",
        "1. **Shallow Network (3 Blocks)**:\n",
        "   - Minimal residual architecture\n",
        "   - Faster training and inference\n",
        "   - Lower model capacity\n",
        "   - Tests if simple features are sufficient\n",
        "\n",
        "2. **Medium Network (5 Blocks)**:\n",
        "   - Balanced depth\n",
        "   - Moderate feature hierarchy\n",
        "   - Good capacity-complexity trade-off\n",
        "   - Tests optimal depth for the task\n",
        "\n",
        "3. **Deep Network (7 Blocks)**:\n",
        "   - Maximum depth tested\n",
        "   - Complex feature hierarchy\n",
        "   - Highest model capacity\n",
        "   - Tests benefits of deeper architecture\n",
        "\n",
        "Key differences:\n",
        "- 3 vs 5 blocks: Evaluates benefit of moderate depth increase\n",
        "- 5 vs 7 blocks: Tests impact of further depth\n",
        "- 3 vs 7 blocks: Contrasts shallow vs deep architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGTWDotgw-Y6"
      },
      "source": [
        "## 4.2 Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6_1_X2NRvRvL"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, GlobalAveragePooling2D, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NEmTkWa7tneb"
      },
      "outputs": [],
      "source": [
        "#@title Model definition functions\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    shortcut = x\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    if stride != 1 or shortcut.shape[-1] != filters:\n",
        "        shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def create_resnet_model(input_shape, num_classes, num_res_blocks):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # First conv-batch-relu-pool block as base layer feature extractor\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "    # Add res blocks for further refinement of features\n",
        "    for _ in range(num_res_blocks):\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    # AVG pool to further compress the results\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSqGZAhsvJ0B"
      },
      "source": [
        "## 4.3 Expirement 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xqJdDSMAxlqA"
      },
      "outputs": [],
      "source": [
        "#@title Choose how many residual blocks to use\n",
        "num_res_blocks = 3 #@param {type:\"integer\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "2Wx_BaFYiehU"
      },
      "outputs": [],
      "source": [
        "#@title Define model\n",
        "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "cnn_model_1 = create_resnet_model(INPUT_SHAPE, NUM_CLASSES, num_res_blocks)\n",
        "\n",
        "# Compile the model\n",
        "cnn_model_1.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "cnn_model_1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GRTW7oYqrIze"
      },
      "outputs": [],
      "source": [
        "#@title Load a pretrained model\n",
        "#@markdown Loading from the set `models_dir`\n",
        "# Load the pre-trained model\n",
        "model_name = \"cnn_model_1\" # @param {\"type\":\"string\"}\n",
        "model_path = models_dir + f'/{model_name}.keras' # Replace with the actual path to your saved model\n",
        "tl1_model = tf.keras.models.load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ew6pW6EZvJ0D"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "cnn1_history = cnn_model_1.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d1N-N3MCvJ0D"
      },
      "outputs": [],
      "source": [
        "#@title Show training loss and accuracy\n",
        "plot_accuracy_along_training(cnn1_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v3JwwwbUvJ0D"
      },
      "outputs": [],
      "source": [
        "#@title Test Model\n",
        "accuracy_1, precision_1, recall_1, f1_1 = test_DL_model(cnn_model_1, test_ds)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_1}\")\n",
        "print(f\"Test Precision: {precision_1}\")\n",
        "print(f\"Test Recall: {recall_1}\")\n",
        "print(f\"Test F1-score: {f1_1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OXZyZ22cPnlS"
      },
      "outputs": [],
      "source": [
        "#@title Save model\n",
        "model_name = \"cnn_model_1\" #@param {\"type\":\"string\"}\n",
        "save_tf_model(cnn_model_1, models_dir, f'{model_name}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gZ3u2XJxQI0"
      },
      "source": [
        "## 4.4 Expirement 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xOH_ccysxxQW"
      },
      "outputs": [],
      "source": [
        "#@title Choose how many residual blocks to use\n",
        "num_res_blocks = 5 #@param {type:\"integer\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "U9jPpPP2xQI1"
      },
      "outputs": [],
      "source": [
        "#@title Define model\n",
        "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "cnn_model_2 = create_resnet_model(INPUT_SHAPE, NUM_CLASSES, num_res_blocks)\n",
        "\n",
        "# Compile the model\n",
        "cnn_model_2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "cnn_model_2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KWyEMiGMxQI1"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "cnn2_history = cnn_model_2.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P3fCk3CzxQI2"
      },
      "outputs": [],
      "source": [
        "#@title Show training loss and accuracy\n",
        "plot_accuracy_along_training(cnn2_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sV2JdmTsxQI2"
      },
      "outputs": [],
      "source": [
        "#@title Test Model\n",
        "accuracy_2, precision_2, recall_2, f1_2 = test_DL_model(cnn_model_2, test_ds)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_2}\")\n",
        "print(f\"Test Precision: {precision_2}\")\n",
        "print(f\"Test Recall: {recall_2}\")\n",
        "print(f\"Test F1-score: {f1_2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-bpTqhMhP6cq"
      },
      "outputs": [],
      "source": [
        "#@title Save model\n",
        "model_name = \"cnn_model_2\" #@param {\"type\":\"string\"}\n",
        "save_tf_model(cnn_model_2, models_dir, f'{model_name}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SddhkAKgx14F"
      },
      "source": [
        "## 4.5 Expirement 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ig4SYUZYx14G"
      },
      "outputs": [],
      "source": [
        "#@title Choose how many residual blocks to use\n",
        "num_res_blocks = 7 #@param {type:\"integer\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ahN-S5pzx14G"
      },
      "outputs": [],
      "source": [
        "#@title Define model\n",
        "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "cnn_model_3 = create_resnet_model(INPUT_SHAPE, NUM_CLASSES, num_res_blocks)\n",
        "\n",
        "# Compile the model\n",
        "cnn_model_3.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "# cnn_model_3.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "U3EacbsEx14G"
      },
      "outputs": [],
      "source": [
        "#@title Train the model\n",
        "cnn3_history = cnn_model_3.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0O4Zg2rax14G"
      },
      "outputs": [],
      "source": [
        "#@title Show training loss and accuracy\n",
        "plot_accuracy_along_training(cnn3_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jaKmSlQVx14G"
      },
      "outputs": [],
      "source": [
        "#@title Test Model\n",
        "accuracy_3, precision_3, recall_3, f1_3 = test_DL_model(cnn_model_3, test_ds)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_3}\")\n",
        "print(f\"Test Precision: {precision_3}\")\n",
        "print(f\"Test Recall: {recall_3}\")\n",
        "print(f\"Test F1-score: {f1_3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zF09iuKGP9xu"
      },
      "outputs": [],
      "source": [
        "#@title Save model\n",
        "model_name = \"cnn_model_3\" #@param {\"type\":\"string\"}\n",
        "save_tf_model(cnn_model_3, models_dir, f'{model_name}.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8aWfiEA31gF"
      },
      "source": [
        "## 4.6 Compare Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Nq5PLnnd31gG"
      },
      "outputs": [],
      "source": [
        "#@title Results\n",
        "# Group history objects\n",
        "histories = [cnn1_history, cnn2_history, cnn3_history]\n",
        "\n",
        "\n",
        "# Compare training history\n",
        "plot_comparison(histories, ['accuracy', 'val_accuracy', 'loss', 'val_loss'])  # Plot Accuracy and Validation Accuracy\n",
        "\n",
        "# Group metrics\n",
        "results = [\n",
        "    [accuracy_1, precision_1, recall_1, f1_1],\n",
        "    [accuracy_2, precision_2, recall_2, f1_2],\n",
        "    [accuracy_3, precision_3, recall_3, f1_3]\n",
        "]\n",
        "\n",
        "# Compare test metrics\n",
        "df_results = compare_test_results(results)\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1dyheRP31gG"
      },
      "source": [
        "## 4.7 Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kUNrKj_231gG"
      },
      "outputs": [],
      "source": [
        "#@title Save\n",
        "\n",
        "save_models = False #@param {type:\"boolean\"}\n",
        "model_type_name = 'cnn' #@param {\"type\":\"string\"}\n",
        "\n",
        "\n",
        "if save_models:\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    cnn_model_1.save(os.path.join(models_dir, f'{model_type_name}_model_1_{timestamp}.keras'))\n",
        "    cnn_model_2.save(os.path.join(models_dir, f'{model_type_name}_model_2_{timestamp}.keras'))\n",
        "    cnn_model_3.save(os.path.join(models_dir, f'{model_type_name}_model_3_{timestamp}.keras'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov-PLGlKO5yq"
      },
      "source": [
        "# Part 5 - Test Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ9M-ZTzQYzP"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from google.colab import files\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng6eEzYbPjAv"
      },
      "outputs": [],
      "source": [
        "#@title Load Best Model <font color=\"red\"> - You need to set this upon your environment\n",
        "best_model_path = '/path/to/best/model.keras'\n",
        "best_model = tf.load_model(best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpmZBy3FQVN4"
      },
      "outputs": [],
      "source": [
        "#@title Upload Files for prediction\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')\n",
        "\n",
        "    # Load the image\n",
        "    img = Image.open(fn)\n",
        "\n",
        "    # Preprocess the image (resize, normalize, etc.)\n",
        "    # Adjust these parameters to match the preprocessing steps used during training\n",
        "    img = img.resize((IMG_SIZE, IMG_SIZE)) # assuming IMG_SIZE is defined elsewhere in your code\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = best_model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    # Plot image\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Class: {predicted_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "52FrgSEzQYWb",
        "UxFQGdYzYffQ",
        "vO7sT7jJ2ZDN",
        "_l0rYOK0MaSB",
        "CaQod3W13qYK",
        "XfGP6AvSjGAb",
        "SJEvw8t1z1P8",
        "CGTWDotgw-Y6",
        "ov-PLGlKO5yq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python3_11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
